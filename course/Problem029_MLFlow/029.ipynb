{
 "cells": [
  {
   "source": [
    "<img src=\"../../img/mldlc2.png\" width=\"900\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## KFold and StratifiedKFold train test split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1, 2], [3, 4], [4, 5], [4, 4], [5, 6], [6, 7], [8, 9], [9, 10], [11, 12]])\n",
    "Y = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2])\n",
    "\n",
    "# 3 Fold split5\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=101)\n",
    "for train_indices, test_indices in kf.split(X, Y):\n",
    "   print(\"train indices:\", train_indices, \"test indices:\", test_indices)\n",
    "   X_train, X_test = X[train_indices], X[test_indices]\n",
    "   Y_train, Y_test = Y[train_indices], Y[test_indices]"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train indices: [1 3 4 5 6 8] test indices: [0 2 7]\ntrain indices: [0 1 2 5 6 7] test indices: [3 4 8]\ntrain indices: [0 2 3 4 7 8] test indices: [1 5 6]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Where printout is Y label of either [0 1 2]\ntrain indices: [2 2 2] test indices: [1 1 1]\ntrain indices: [2 2 2] test indices: [1 1 1]\ntrain indices: [2 2 2] test indices: [1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#StratifiedKFold distributes the target labels within fold in same ratio in which they appear in main dataset\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# TBD: Use StratifiedKFold to split X and Y into 3 fold train test set and verify that all the three target labels (0, 1, 2) are present in each fold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=101)\n",
    "print(\"Where printout is Y label of either [0 1 2]\")\n",
    "for train_indices, test_indices in skf.split(X, Y):\n",
    "   print(\"train indices:\", np.bincount(Y[train_indices]), \"test indices:\", np.bincount(Y[test_indices]))\n",
    "   X_train, X_test = X[train_indices], X[test_indices]\n",
    "   Y_train, Y_test = Y[train_indices], Y[test_indices]"
   ]
  },
  {
   "source": [
    "## GridSearch CV (Search for a best set of hyperparams for a given model)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "51.9764391951006\n"
     ]
    }
   ],
   "source": [
    "# Load Boston housing dataset\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X, Y = load_boston(return_X_y=True)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=101)\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=3)\n",
    "model.fit(X_train, Y_train)\n",
    "Y_hat = model.predict(X_test)\n",
    "print(mean_squared_error(Y_test, Y_hat))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best: -0.2893603144554894 using {'n_neighbors': 8}\n-0.472560526236681,0.6315156892215512 with: {'n_neighbors': 2}\n-0.3805458677224257,0.5212934092505351 with: {'n_neighbors': 3}\n-0.320685224628445,0.4690431891197771 with: {'n_neighbors': 4}\n-0.31501646812514134,0.4401304871369981 with: {'n_neighbors': 5}\n-0.32567751357459207,0.42432013741134633 with: {'n_neighbors': 6}\n-0.30533542609085224,0.411918977909927 with: {'n_neighbors': 7}\n-0.2893603144554894,0.41702218187230644 with: {'n_neighbors': 8}\n53.535024606299196\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def grid_summary(grid_result):\n",
    "    print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(f\"{mean},{stdev} with: {param}\")  \n",
    "\n",
    "## TBD Using GridSearchCV check which value of param n_neighbors [2,3,4,5,6,7,8] gives the best results\n",
    "\n",
    "parameters = {'n_neighbors':[2,3,4,5,6,7,8]}\n",
    "gs = GridSearchCV(KNeighborsRegressor(), parameters)\n",
    "gs.fit(X, Y)\n",
    "grid_summary(gs)\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=8)\n",
    "model.fit(X_train, Y_train)\n",
    "Y_hat = model.predict(X_test)\n",
    "print(mean_squared_error(Y_test, Y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best: -0.18954795135784916 using {'n_neighbors': 4, 'p': 1}\n-0.22813976586145773,0.37412693921633206 with: {'n_neighbors': 2, 'p': 1}\n-0.472560526236681,0.6315156892215512 with: {'n_neighbors': 2, 'p': 2}\n-0.19870846489933208,0.27283333973737306 with: {'n_neighbors': 3, 'p': 1}\n-0.3805458677224257,0.5212934092505351 with: {'n_neighbors': 3, 'p': 2}\n-0.18954795135784916,0.2697094749115022 with: {'n_neighbors': 4, 'p': 1}\n-0.320685224628445,0.4690431891197771 with: {'n_neighbors': 4, 'p': 2}\n-0.21680588831552852,0.27043478274620825 with: {'n_neighbors': 5, 'p': 1}\n-0.31501646812514134,0.4401304871369981 with: {'n_neighbors': 5, 'p': 2}\n-0.23357953948492266,0.27525142963576954 with: {'n_neighbors': 6, 'p': 1}\n-0.32567751357459207,0.42432013741134633 with: {'n_neighbors': 6, 'p': 2}\n-0.21520341623298894,0.2713440687332639 with: {'n_neighbors': 7, 'p': 1}\n-0.30533542609085224,0.411918977909927 with: {'n_neighbors': 7, 'p': 2}\n-0.21537623850471013,0.2718811820617129 with: {'n_neighbors': 8, 'p': 1}\n-0.2893603144554894,0.41702218187230644 with: {'n_neighbors': 8, 'p': 2}\n40.396855314960625\n"
     ]
    }
   ],
   "source": [
    "## TBD Using GridSearchCV check which value of param combination n_neighbors [2,3,4,5,6,7,8], p [1, 2] gives the best result\n",
    "\n",
    "parameters = {'n_neighbors':[2,3,4,5,6,7,8], 'p':[1,2]}\n",
    "gs2 = GridSearchCV(KNeighborsRegressor(), parameters)\n",
    "gs2.fit(X, Y)\n",
    "grid_summary(gs2)\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=4, p=1)\n",
    "model.fit(X_train, Y_train)\n",
    "Y_hat = model.predict(X_test)\n",
    "print(mean_squared_error(Y_test, Y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gridsearch across different algorithms\n",
    "\n",
    "## TBD Create a ML pipeline that selects the best model-param combination among given set of models and params\n",
    "* LinearRegression, No params\n",
    "* KNeighborsRegressor, params: {n_neighbors : [4,5,6], p: [1,2]}\n",
    "* XGBoost, params : {}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = load_boston(return_X_y=True)\n",
    "\n",
    "# [(model_1, param_1), (model_2, param_2), ...]\n",
    "def model_param_optimiser(models):\n",
    "    searches = []\n",
    "    top = 0\n",
    "    for model in models:\n",
    "        gs = GridSearchCV(model[0], model[1], scoring='neg_mean_squared_error')\n",
    "        gs.fit(X_train, Y_train)\n",
    "        searches.append(gs)\n",
    "    for i in range(len(searches)):\n",
    "        if (abs(searches[i].best_score_) < abs(searches[top].best_score_)):\n",
    "            top = i\n",
    "    print(\"Top Score:\" + str(searches[top].best_score_))\n",
    "    print(\"Model:\" + str(models[top][0]))\n",
    "    print(\"Params:\" + str(searches[top].best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top Score:-9.342108246852757\nModel:GradientBoostingRegressor()\nParams:{'max_depth': 3, 'n_estimators': 200, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "no_param = {}\n",
    "parameters_knn = {'n_neighbors':[4,5,6], 'p':[1,2]}\n",
    "parameters_xgboost = {'n_estimators': [50,100,200], 'max_depth': [2,3,4,5,6,7], 'subsample': [0.9, 1.0, 1.1] }\n",
    "models = [(LinearRegression(), no_param), (KNeighborsRegressor(), parameters_knn), (GradientBoostingRegressor(), parameters_xgboost)]\n",
    "\n",
    "model_param_optimiser(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best: -11.147465290168133 using {'model': GradientBoostingRegressor(n_estimators=200), 'model__max_depth': 3, 'model__n_estimators': 200}\n-23.27512074085658,5.893867833178617 with: {'model': LinearRegression()}\n-37.98679633795775,8.188123345748794 with: {'model': KNeighborsRegressor(), 'model__n_neighbors': 2, 'model__p': 1}\n-43.791816231304416,6.737895664076707 with: {'model': KNeighborsRegressor(), 'model__n_neighbors': 2, 'model__p': 2}\n-34.8176881362052,8.340147227383387 with: {'model': KNeighborsRegressor(), 'model__n_neighbors': 3, 'model__p': 1}\n-40.206412369750076,9.996662292923505 with: {'model': KNeighborsRegressor(), 'model__n_neighbors': 3, 'model__p': 2}\n-35.03843062585927,9.585274537229507 with: {'model': KNeighborsRegressor(), 'model__n_neighbors': 4, 'model__p': 1}\n-39.84197515675124,11.012985445863649 with: {'model': KNeighborsRegressor(), 'model__n_neighbors': 4, 'model__p': 2}\n-16.466610086916226,2.8767255760957626 with: {'model': GradientBoostingRegressor(n_estimators=200), 'model__max_depth': 2, 'model__n_estimators': 50}\n-15.868425622793177,2.344279094245705 with: {'model': GradientBoostingRegressor(n_estimators=200), 'model__max_depth': 2, 'model__n_estimators': 100}\n-15.86820631943956,2.350900968182791 with: {'model': GradientBoostingRegressor(n_estimators=200), 'model__max_depth': 2, 'model__n_estimators': 200}\n-11.27147628603778,1.7970435366835202 with: {'model': GradientBoostingRegressor(n_estimators=200), 'model__max_depth': 3, 'model__n_estimators': 50}\n-11.380299539449574,1.7909603077020937 with: {'model': GradientBoostingRegressor(n_estimators=200), 'model__max_depth': 3, 'model__n_estimators': 100}\n-11.147465290168133,1.642097625825169 with: {'model': GradientBoostingRegressor(n_estimators=200), 'model__max_depth': 3, 'model__n_estimators': 200}\n-12.804023840374386,2.5893153987784574 with: {'model': GradientBoostingRegressor(n_estimators=200), 'model__max_depth': 4, 'model__n_estimators': 50}\n-11.863215435975242,2.1065796952959093 with: {'model': GradientBoostingRegressor(n_estimators=200), 'model__max_depth': 4, 'model__n_estimators': 100}\n-13.09759287398491,1.8800286409457598 with: {'model': GradientBoostingRegressor(n_estimators=200), 'model__max_depth': 4, 'model__n_estimators': 200}\n-14.319153944426892,0.76515811295676 with: {'model': GradientBoostingRegressor(n_estimators=200), 'model__max_depth': 5, 'model__n_estimators': 50}\n-13.610693486234231,1.716649350005844 with: {'model': GradientBoostingRegressor(n_estimators=200), 'model__max_depth': 5, 'model__n_estimators': 100}\n-14.596480295778308,1.8480967250993343 with: {'model': GradientBoostingRegressor(n_estimators=200), 'model__max_depth': 5, 'model__n_estimators': 200}\n-13.58594736998679,0.8400341882365276 with: {'model': GradientBoostingRegressor(n_estimators=200), 'model__max_depth': 6, 'model__n_estimators': 50}\n-13.578757987229254,0.010558394164556898 with: {'model': GradientBoostingRegressor(n_estimators=200), 'model__max_depth': 6, 'model__n_estimators': 100}\n-13.216451929136133,1.1745126243461372 with: {'model': GradientBoostingRegressor(n_estimators=200), 'model__max_depth': 6, 'model__n_estimators': 200}\n-14.67235512269871,1.694622349479619 with: {'model': GradientBoostingRegressor(n_estimators=200), 'model__max_depth': 7, 'model__n_estimators': 50}\n-14.9186558784529,1.3845411858304366 with: {'model': GradientBoostingRegressor(n_estimators=200), 'model__max_depth': 7, 'model__n_estimators': 100}\n-14.119290661721474,1.883510089732982 with: {'model': GradientBoostingRegressor(n_estimators=200), 'model__max_depth': 7, 'model__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import  Pipeline\n",
    "pipe  = Pipeline([('model', LinearRegression())])\n",
    "param_grid = [\n",
    "              {'model' : [LinearRegression()]},\n",
    "              {'model' : [KNeighborsRegressor()], 'model__n_neighbors': [2,3,4], 'model__p': [1,2]},\n",
    "              {'model' : [GradientBoostingRegressor()], 'model__n_estimators': [50,100,200], 'model__max_depth': [2,3,4,5,6,7] }\n",
    "            ]\n",
    "\n",
    "grid = GridSearchCV(estimator=pipe, param_grid=param_grid, cv=3, scoring = 'neg_mean_squared_error')\n",
    "\n",
    "res = grid.fit(X_train, Y_train)\n",
    "grid_summary(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}