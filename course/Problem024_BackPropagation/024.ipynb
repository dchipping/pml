{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "\n",
    "### TBD: What is being back propagated?\n",
    "     \n",
    "<img src=\"../../img/nn_backprop_simplest1.png\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "### TBD: In the above setup \n",
    "     - How many functions are involved?\n",
    "     - How many weights are involved?\n",
    "     - With only one training sample x=3, y=2 and weights w1=0.5, w2=0.8 Whats y_hat?\n",
    "     - Whats the MSE Cost?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = x*w1 = 3*0.5 = 1.5\n",
    "a1 = ReLU(z1) = 1.5\n",
    "z2 = a1*w2 = 1.5*0.8 = 1.2\n",
    "y_hat = ReLU(z2) = 1.2\n",
    "J = (y - y_hat)^2 = (2 - 1.2)^2 = 0.64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Just expanded the above neural network to show weighted sum and activation components\n",
    "\n",
    "<img src=\"../../img/nn_backprop_simplest_expanded1.png\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "### TBD To go backward, compute the following for previously given weights and training sample\n",
    "     \n",
    " $\\begin{align}\\frac{dJ}{d\\hat{y}}\\end{align}$\n",
    " $\\begin{align}\\frac{d\\hat{y}}{dz2}\\end{align}$\n",
    " $\\begin{align}\\frac{dz2}{dw2}\\end{align}$\n",
    " $\\begin{align}\\frac{dz2}{da1}\\end{align}$\n",
    " $\\begin{align}\\frac{da1}{dz1}\\end{align}$\n",
    " $\\begin{align}\\frac{dz1}{dw1}\\end{align}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dJ/dy_hat = -2(y-y_hat) = -2(0.8) = -1.6\n",
    "dy_hat/dz2 = ReLU'(z2) = 1\n",
    "dz2/dw2 = a1 = 1.5\n",
    "dz2/da1 = w2 = 0.8\n",
    "da1/dz1 = ReLU'(z1) = 1\n",
    "dz1/dw1 = x = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How cost changes with weights?\n",
    " \n",
    " Whole purpose of back propagation or this notebook is to compute \n",
    " _**how cost changes with weights**_ i.e\n",
    " \n",
    " $\\begin{align}\\frac{dJ}{d weights}\\end{align}$\n",
    " \n",
    " \n",
    "### TBD What are the values of:\n",
    " \n",
    "a) $\\begin{align}\\frac{dJ}{dw1}\\end{align}$\n",
    "  \n",
    "  \n",
    "b) $\\begin{align}\\frac{dJ}{dw2}\\end{align}$\n",
    "  \n",
    "_(Hint: Use Chain Rule & above results)_\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dJ/dw1:\n",
    "    = dJ/dy_hat * dy_hat/dz2 * dz2/da1 * da1/dz1 * dz1/dw1\n",
    "    = -1.6 * 1 * 0.8 * 1 * 3\n",
    "    = -3.84\n",
    "dJ/dw2:\n",
    "    = dJ/dy_hat * dy_hat/dz2 * dz2/dw2\n",
    "    = -1.6 * 1 * 1.5\n",
    "    = -2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Weights\n",
    "\n",
    "### TBD: In the above problem after you have computed \n",
    "$\\begin{align}\\frac{dJ}{dw1}\\end{align}$ and\n",
    "$\\begin{align}\\frac{dJ}{dw2}\\end{align}$\n",
    "\n",
    "what are new weights if the learning rate is 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w* = w - dJ/dw * LR\n",
    "w1*:\n",
    "    = w1 - dJ/dw1 * LR\n",
    "    = 0.5 - (-3.84) * 0.1\n",
    "    = 0.884\n",
    "w2*:\n",
    "    = w2 - dJ/dw2 * LR\n",
    "    = 0.8 - (-2.4) * 0.1\n",
    "    = 1.04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Again\n",
    "\n",
    "### TBD: Plug in those new weights and check if the cost is reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = x*w1 = 3*0.884 = 2.652\n",
    "a1 = ReLU(z1) = 2.652\n",
    "z2 = a1*w2 = 2.652*1.04 = 2.75 \n",
    "y_hat = ReLU(z2) = 2.75\n",
    "J = (y - y_hat)^2 = (2 - 2.75)^2 = 0.56\n",
    "\n",
    "0.64 - 0.56 = 0.08\n",
    "Cost Reduction of 0.08"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
